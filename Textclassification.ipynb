{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7a198e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              sentence  label source\n",
      "0                             Wow... Loved this place.      1   yelp\n",
      "1                                   Crust is not good.      0   yelp\n",
      "2            Not tasty and the texture was just nasty.      0   yelp\n",
      "3    Stopped by during the late May bank holiday of...      1   yelp\n",
      "4    The selection on the menu was great and so wer...      1   yelp\n",
      "..                                                 ...    ...    ...\n",
      "743  I just got bored watching Jessice Lange take h...      0   imdb\n",
      "744  Unfortunately, any virtue in this film's produ...      0   imdb\n",
      "745                   In a word, it is embarrassing.        0   imdb\n",
      "746                               Exceptionally bad!        0   imdb\n",
      "747  All in all its an insult to one's intelligence...      0   imdb\n",
      "\n",
      "[2748 rows x 3 columns]\n",
      "Of all the dishes, the salmon was the best, but all were great.\n",
      "[11, 43, 1, 171, 1, 283, 3, 1, 47, 26, 43, 24, 22]\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 100, 100)          174700    \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 96, 128)           64128     \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 240,129\n",
      "Trainable params: 240,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training Accuracy: 1.0000\n",
      "Testing Accuracy:  0.7920\n"
     ]
    }
   ],
   "source": [
    "# Load the libraries\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.utils import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Load the path for the dataset\n",
    "\n",
    "filepath_dict = {'yelp':   'data/sentiment_analysis/yelp_labelled.txt',\n",
    "                 'amazon': 'data/sentiment_analysis/amazon_cells_labelled.txt',\n",
    "                 'imdb':   'data/sentiment_analysis/imdb_labelled.txt'}\n",
    "\n",
    "# Create an empty list  to loop through the dataset\n",
    "df_list = []\n",
    "for source, filepath in filepath_dict.items():\n",
    "    df = pd.read_csv(filepath, names=['sentence', 'label'], sep='\\t')\n",
    "    df['source'] = source  # Add another column filled with the source name\n",
    "    df_list.append(df)\n",
    "\n",
    "#Concatenate the list to a dataframe\n",
    "df = pd.concat(df_list)\n",
    "print(df)\n",
    "\n",
    "#Assigning values to labels and spliting the dataset into train, test\n",
    "df_yelp = df[df['source']=='yelp']\n",
    "sentences = df_yelp['sentence'].values\n",
    "y = df_yelp['label'].values\n",
    "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size = 0.25, random_state = 1000)\n",
    "\n",
    "# Generating the dataset\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(sentences_train)\n",
    "\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
    "X_test = tokenizer.texts_to_sequences(sentences_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "\n",
    "# Checking the dataset\n",
    "print(sentences_train[2])\n",
    "print(X_train[2])\n",
    "\n",
    "embedding_dim = 100\n",
    "maxlen = 100\n",
    "\n",
    "X_train = pad_sequences(X_train, padding = 'post', maxlen= maxlen)\n",
    "X_test = pad_sequences(X_test, padding = 'post', maxlen= maxlen)\n",
    "\n",
    "# Developing the model with Convolution of 1d\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Training the model with dataset\n",
    "history= model.fit(X_train, y_train,\n",
    "                  epochs = 10,\n",
    "                  verbose = False,\n",
    "                  validation_data = (X_test, y_test),\n",
    "                  batch_size = 10)\n",
    "\n",
    "# Evaluating the model to obtain the accuracy and loss for the testing and training\n",
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
